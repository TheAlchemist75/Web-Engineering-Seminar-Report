<!DOCTYPE html>
<html>

<head>
    <title>Web Engineering Seminar</title>

    <link rel="stylesheet" type="text/css" href="main.css" />
    <link href='https://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
</head>

<body>
    <header>
        <h2>Web Engineering Seminar in Winter-semester 2023/24</h2>
        <h1>Trust-Aware Decision Making</h1>
        <h2 class="author">Shubham Manur and Farid Mammadov</h2>
        <h3 class="affiliation">
            Advisor: Valentin Siegert<br>
            Professorship of Distributed and Self-Organising Computer Systems<br>
            Technical University of Chemnitz<br>
            Chemnitz, Germany
        </h3>
    </header>

    <div id="section1">
        <h2>1. Introduction <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>

        <p>In the field of machine learning making decisions often relies on analyzing data and identifying patterns. However when
        it comes to real life situations there's a factor that comes into play; trust. Trust plays a pivotal role, in todays
        interconnected world. It greatly influences the effectiveness and reliability of decision making processes. To account
        for this aspect, trust aware decision making incorporates factors related to trust into the decision making framework.</p>
        
        <p>In areas such as artificial intelligence, human computer interaction and autonomous systems recognizing and integrating 
            trust is essential for decision making. This approach evaluates the dependability, credibility and past performance of 
            individuals or entities involved in order to ensure that decisions aren't solely based on data but also take into account the level 
            of trustworthiness associated with them. This raises the question; why does trust matter and what significance does it hold? 
            In this report we will explore how incorporating information related to trust into machine learning models can result in outcomes 
            that're not only more robust and transparent but also align, with principles that prioritize user satisfaction. </p>
    </div>
    
    <div id="section2">
        <h2>2. Trustworthy AI vs Trust-aware Decision Making <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>
        
        <p>Trustworthy AI and Trust aware decision making although sometimes used interchangeably are actually two interconnected
        concepts. Trustworthy AI encompasses a framework that addresses the trustworthiness of AI systems. This framework
        includes factors such, as accuracy, reliability, fairness, security and transparency. <a href="#r1">[1]</a>.
        On the hand Trust aware decision making operates within the framework of trustworthy AI. It specifically focuses on the
        decision making processes employed by AI systems. Emphasizes the significance of transparency, explainability and
        accountability in establishing trust and minimizing biases or ethical concerns.</p>
        
        <p>In order to develop AI it is crucial to integrate the principles of trust decision making. Transparency involves
        providing explanations of AI decisions to humans so that they can understand why certain actions were taken by the
        system. <a href="#r1">[1]</a>. Explainability goes beyond transparency by delving into the underlying data and algorithms that inform AI decisions
        enabling an understanding of how the system arrives at its reasoning. Accountability ensures that AI systems can be held
        responsible, for their decisions so that individuals affected by these outcomes have recourse if necessary. <a href="#r1">[1]</a>.
        By incorporating these principles trust aware decision making significantly contributes to the development of AI systems
        that're not just accurate and reliable but transparent, explainable and accountable.</p>
    </div>

    <div id="section3">
        <h2>3. Key Components <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>
        
        <p>Now lets delve into the components of trust decision making. Exploring these elements will provide us with an
        understanding of how trust intersects with decision making processes.</p>
        
        <h3>3.1. Integration of Trust Considerations</h3>

        <p>Improving decision making procedures requires integrating elements related to trust. This entails creating models and
        algorithms of assessing the reliability and credibility of entities within the decision making context such as data
        sources, algorithms or individuals. For instance in sensor networks trust management plays a role in guaranteeing secure
        data transmission and decision making. Trust management schemes typically involve establishing relationships, between
        sensor nodes based on their behavior and reputation. These relationships are then utilized to filter and prioritize data
        effectively while making decisions regarding routing and resource allocation. <a href="#r2">[2]</a>.</p>

        <h3>3.2. Multidisciplinary Application</h3>
        
        <p>Trust-aware decisions involve a comprehensive approach that takes into account the trustworthiness of various elements.
        This means considering the reliability and credibility of involved entities, ultimately leading to more dependable
        outcomes across diverse fields. For instance, in AI, algorithms may be designed to consider the trustworthiness of data
        sources to improve the quality of predictions or classifications. In human-computer interaction, trust is crucial for
        user acceptance and satisfaction. Autonomous systems, relying on decision-making algorithms, benefit from incorporating
        trust metrics to ensure safe and reliable operations.</p>
    </div>

    <div id="section4">
        <h2>4. Decision-making process <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>
        
        <p>We have categorized our topic into three ideas, within the umbrella of Trust Aware Decision Making; Decision Making in
        Artificial Intelligence, Robots and Autonomous Systems. In domains such as AI, human computer interaction and
        autonomous systems it is crucial to understand and incorporate trust for decision making</p>
        
        <h3>4.1. Decision-making in Artificial Intelligence</h3>
        
        <p>When it comes to Artificial Intelligence (AI) employing algorithms and complex data analysis is essential for optimizing
        actions. However the opaqueness and complexity of AI systems often create challenges in establishing trust among users.
        On the hand AI systems can also be designed to be more transparent and accountable which can contribute to building
        trust <a href="#r3">[3]</a>.</p>
        
        <p>It becomes crucial to design AI systems with transparency and accountability in order to foster trust. This is where
        dynamic decision adjustment plays a role by enabling AI systems to adapt to changing circumstances across fields such as
        finance, healthcare and autonomous systems. An important aspect, in building trust within AI is AI (XAI).
        
        Developing models that offer explanations, for AI decisions is crucial to establish trust and acceptance from users,
        stakeholders and regulatory bodies. The idea of Human AI collaboration highlights the relationship between AI systems
        and human intelligence. While AI brings efficiency and automation human involvement adds understanding, ethical
        considerations and a deeper comprehension of situations <a href="#r3">[3]</a>. IBM's Watson for Oncology provides an example of decision making in AI. It is developed in partnership, with Memorial
        Sloan Kettering Cancer Center leveraging literature, clinical trial data and oncology textbooks. This system showcases
        how human intelligence and AI capabilities work together harmoniously to achieve decision making outcomes <a href="#r4">[4]</a> <a href="#r5">[5]</a>.</p>
        
        <h3>4.2. Decision-making in Robots</h3>
        
        <p>Decision making, in robotics goes beyond algorithms it also involves considering the reliability of input and building
        trust in interactions between humans and robots. Ongoing research in these areas plays a role in ensuring that robots
        are robust, adaptable and accepted across applications <a href="#r6">[6]</a>.</p>
        
        <p>Lets delve into aspects, Sensor Trustworthiness focuses on assessing how dependable the sensory input is. This includes
        methods to evaluate and enhance the trustworthiness of data collected by robot sensors evaluating sensor accuracy,
        calibration techniques and real time reliability. Adaptive Algorithms highlight the importance of using decision making
        algorithms that can adapt to unpredictable scenarios effectively <a href="#r7">[7]</a>. Lastly Human Robot Trust emphasizes the role of establishing trust between humans and robots for collaboration.
        Understanding how users perceive trust in actions is significant, for deploying robotic systems <a href="#r7">[7]</a>. 
        Nikes collaborative robot, known as a cobot serves as an example of the decision making capabilities, in robotics.
        Unlike robots that are typically confined to cages or enclosures to prevent interactions with humans cobots are equipped
        with sensors and software that enable them to detect and avoid collisions. The cobots impressive ability to efficiently
        handle parts with speed and precision has led to order fulfillment and reduced processing times. As a result Nike was
        able to introduce same day delivery services for its customers. <a href="#r8">[8]</a>.</p>
        
        <h3>4.3. Decision-making in Autonomous systems</h3>
        
        <p>As humans increasingly rely on systems for decision making it becomes essential to ensure the trustworthiness of these
        systems. Trust encompasses elements such, as reliability, predictability and fairness while also aligning with values
        and expectations <a href="#r9">[9]</a>.</p>
        
        <p>An important way to build trust in the decision making process of systems is, by using metrics based on data. It becomes
        crucial to evaluate the reliability of the data inputs from the environment <a href="#r9">[9]</a>. Decentralized trust models provide an approach that enables decision making based on trust assessments within a network.
        This collaborative behavior significantly enhances the dependability of decision making in complex systems like
        transportation. A key aspect in establishing trust is learning and adaptation. Trust evolves through experiences and interactions. Decision models that are aware of trust need to possess the ability
        to continuously learn from their environment and interactions. They should be adaptable enough to adjust their trust
        assessments and decision making strategies as the landscape changes <a href="#r9">[9]</a> <a href="#r10">[10]</a>.
        Lets take a look, at Waymo, a known player in the field of driving to see how they demonstrate the practical application
        of a reliable decision making framework. Waymo, which operates under Alphabet Inc. is at the forefront of developing
        vehicles that can navigate real world situations without intervention. What sets Waymo apart is its decision making
        framework, which prioritizes safety, transparency and adaptability. This approach embodies the idea of building trust
        through autonomy <a href="#r11">[11]</a>.</p>
    </div>

    <div id="section5">
        <h2>5. Creating Trust-aware decisions <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>
        
        <p>Now that we've explored these aspects lets delve into how trust aware decision making can be incorporated in ways:</p>
        
        <h3>5.1. Transparency</h3>

        <p> One noteworthy concept is achieving trust by focusing on transparency. Transparent systems offer users insights into the
        decision making process ensuring that they can easily understand the reasoning, behind each decision. When users can
        trace and comprehend the steps leading to an outcome they are more likely to place their trust in those decisions <a href="#r3">[3]</a> <a href="#r12">[12]</a>.</p>

        <h3>5.2. Adaptive Decision-Making</h3>
        
        <p>In order to make decisions it is important for trust aware systems to adapt to changing circumstances and evolving
        information. This involves the ability to adjust strategies based on real time feedback and changes, in the environment.
        By incorporating learning algorithms and continuously monitoring the situation these systems can respond to shifts in
        trust levels ensuring that decisions remain relevant and reliable over time <a href="#r7">[7]</a>.</p>
        
        <h3>5.3. Diversify Inputs</h3>

        <p>To build trust it is beneficial for trust decisions to consider a range of inputs. Of relying on one source or type of
        information incorporating varied and complementary data inputs can enhance the decision making process <a href="#r13">[13]</a>.</p>
        
        <h3>5.4. Explainability Techniques</h3>

        <p>The concept of trust is closely linked to the need for explanations of decisions. Techniques aimed at explainability
        help users understand decision making processes better. Methods such as analyzing feature importance using models and
        interactive visualizations contribute towards creating an understandable framework for decision making. The ability to
        provide explanations plays a role, in building user confidence and acceptance of automated decision making systems <a href="#r14">[14]</a>.</p>
    </div>

    <div id="section6">
        <h2>6. Challenges and Drawbacks <span style="font-size: 12px;">[Written by Shubham Manur]</span></h2>
        
        <p>Trust aware decision making, although an evolving field, does have its drawbacks. The following limitations shed light
        on some of the concerns, in this area:</p>
        
        <h3>6.1. Lack of Transparency and Explainability</h3>

        <p>One of the challenges in trust aware decision making is the lack of transparency and explainability. When decision
        making processes are not clear or difficult to understand (like a black box) users may find it hard to trust the
        outcomes. To overcome this challenge it is necessary to develop strategies, for making decision making processes more
        transparent and implementing techniques that help users understand algorithms better <a href="#r4">[4]</a> <a href="#r14">[14]</a>.</p>
        
        <h3>6.2. Security Concerns</h3>

        <p>Security concerns present an obstacle, for decision making systems that prioritize trust. Since these systems handle
        information and make choices they become attractive targets for malicious activities such as hacking or manipulation. It
        is crucial to establish cybersecurity measures, including encryption, secure data storage and access controls in order
        to ensure the reliability and safety of decision making processes <a href="#r2">[2]</a>.</p>
        
        <h3>6.3. Human-AI Collaboration</h3>

        <p>In situations where the consequencesre significant users might feel hesitant about relying solely on AI systems for
        decision making. Finding the balance between intuition and insights provided by AI is a delicate task. By managing the
        roles of both humans and AI we can capitalize on their strengths while also addressing any biases or misunderstandings.
        This approach plays a role, in fostering trust within environments <a href="#r9">[9]</a> <a href="#r15">[15]</a>.</p>
    </div>

    <div id="section7">
        <h2>7. Trust-aware decision-making in decentralized applications <span style="font-size: 12px;">[Written by Farid Mammadov]</span></h2>

        <p>The flow of data and information on the web has historically been controlled by a few large corporations or other
        entities, making the web somewhat centralized. Decentralization seeks to disperse this power, enabling a web experience
        that is more user-controlled and democratic. Critical to web innovation, decentralized web applications require
        autonomous trust evaluation mechanisms. They must assess the reliability of data from various sources, many of which are
        unknown or confidential, and incorporate contextual and contextual trust factors to improve security and functionality
        in the absence of central authority control <a href="#r16">[16]</a>. Decentralized knowledge graphs, which are free from centralized control, gather data from multiple autonomous sources
        into a single, unified network, enabling sophisticated search, integration, and query capabilities across a wide range
        of domains <a href="#r19">[19]</a>.</p>

        <p>We have to aim to provide efficient and scalable query processing techniques over such decentralized knowledge graphs to
        accommodate for quick and continuous access to the information within knowledge graphs when multiple requests are sent
        simultaneously. Blockchains are a method of data distribution; They can be used to reduce the likelihood of malicious
        updates.[17] Blockchain’s decentralization enables peer-to-peer transactions without the need for central authority
        validation, also reducing server costs. It guarantees safe, open transactions. However, it has problems with energy
        consumption and scalability, especially in systems that use energy-intensive consensus techniques <a href="#r18">[18]</a>.</p>

        <h3>7.1. Influence on Trust-aware Decision-making</h3>

        <p>In a scenario where web applications dynamically acquire data from decentralized knowledge graphs and other distributed
        web data stores have a significant and multifaceted influence on trust-aware decision-making: <br><br>
        (a) Here all the applications must continually assess the trustworthiness of the data that they collect <a href="#r22">[22]</a>. The reason is
        that data is not retrieved from various decentralized sources. The data might be stored with various security and in
        their controlled environment <a href="#r20">[20]</a>. <br><br>
        (b) Based on the assessments must make real-time decisions about whether to reject or accept the data. These decisions
        analyze the data’s source, its consistency, and trustworthiness.<br><br>
        (c) Trust models that rely on predefined trust paths, may not be completely appropriate because the data sources are
        decentralized in a more distributed manner where every application creates its trust parameters <a href="#r21">[21]</a>.<br><br>
        (d) Applications must adapt to a wide range of data sources and types, each with a unique level of trustworthiness. To
        manage and handle the scalability and diversity of the data, trust-aware processes must be highly automated and
        autonomous.<br><br>
        (e) As multiple applications interact with the same data, addressing potential issues like inconsistencies or manipulations
        by other services is important. Applications require mechanisms to handle issues in data.<br><br>
        (f) Creation of trust testimonials: Trust testimonials are artifacts that demonstrate the trustworthiness of entities. Every
        application may need to create these testimonials to inform its trust decisions <a href="#r22">[22]</a>.</p>
    </div>

    <div id="section8">
        <h2>8. Case Study - Review Aggregator <span style="font-size: 12px;">[Written by Farid
                Mammadov]</span></h2>
        
        <p>Digital platforms known as web aggregators are dedicated to gathering and evaluating data from various online data
        sources <a href="#r23">[23]</a>. After gathering all these reviews, the product aggregator finds the average of them just to produce a
        final result. This rating helps potential customers to figure out the advantages and also disadvantages of using the
        products and goods. With the help of this tool, businesses can monitor customer feedback regarding both their strengths
        and areas for improvement. Customers perceive it as similar to having a friend who shares their first-hand experience
        after trying something. These review aggregators help everyone make informed decisions and foster trust between
        consumers and businesses, much like the storytellers of the digital world.</p>

        <h3>8.1. Benefits of Review Aggregators</h3>

        <p>The way consumers assess product reviews has been completely transformed by feedback platforms. These platforms have
        greatly decreased the time and effort needed for customers to locate and read reviews by compiling reviews from various
        sources into a single, easily accessible location. A thorough summary of client experiences and testimonials is provided
        by this information centralization, giving consumers a wide-ranging viewpoint on goods and services. Customers find it
        simpler to make prompt, well-informed decisions thanks to these platforms' effectiveness in aggregating a variety of
        viewpoints. Review aggregators, which streamline the research process and give customers greater confidence when making
        purchases, have consequently emerged as an essential tool in contemporary consumer behaviour. Convenience and
        comprehensiveness are valued in the evolving world of online shopping and information consumption, which is reflected in
        their growing importance.</p>

        <p>In many industries, valuing customer reviews via aggregation platforms has become essential, giving consumers and
        companies alike a useful tool for gauging overall customer satisfaction and product quality. These platforms
        meticulously gather and synthesize feedback from various sources, transforming disorganized concepts into
        comprehensible, easily absorbed synopses. This streamlines the process of gaining access to group reviews considerably
        and offers a thorough overview of user experiences. Because of this, customers can use data from various angles to make
        well-informed decisions. Businesses can use this information to promote a customer-focused approach to service and
        product development and to identify areas of strength and improvement. In addition to offering a consolidated view of
        customer feedback to assist consumers in making decisions, aggregation platforms are crucial in influencing business
        strategies and improving customer experience in a competitive market.</p>

        <p>Review aggregation platforms are advantageous to businesses as well as users because they give access to a plethora of
        customer experiences, saving time. Better decision-making is facilitated by this feature, which puts the customer first
        in the marketplace. More and more decisions are being made based on the preferences and expectations of the individual,
        demonstrating the growing power of the consumer and influencing businesses' product and marketing strategies.</p>
    </div>

    <div id="section9">
        <h2>9. Use of Artificial Intelligence in trust-aware decision-making <span style="font-size: 12px;">[Written by Farid
                Mammadov]</span></h2>

        <p>Artificial intelligence, a technology that copies human intelligence, is being adopted by businesses <a href="#r25">[25]</a>. Researchers
        are now more interested in understanding how to make the members adapt to the trust AI systems. To integrate AI for
        decision-making in businesses, employee trust is considered the most essential factor out of all. Trust is the critical
        component of transparency <a href="#r25">[25]</a>. AI is more complex than other technologies when it comes to deep learning models.</p>

        <p>Artificial Intelligence has the potential to greatly improve decision-making processes. AI also increases the
        recommendation systems and performances of management systems. However, AI is mostly dependent on employee trust <a href="#r26">[26]</a>.
        Because AI has an impact on employees, trust is essential. Acceptance of AI-generated decisions is influenced by their
        level of trust in the technology, which may also have an impact on their attitudes to the decisions in general and
        because this trust becomes more important it is fair to say that AI is the main factor in trust-aware decision making.</p>

        <h3>9.1. Advantages</h3>

        <p>(a) The accuracy and applicability of decisions are greatly improved when AI is incorporated. AI algorithms possess the
        ability to examine extensive datasets, detect trends, and offer the best solutions for decision-making <a href="#r27">[27]</a>. AI reduces
        the human error that might happen in business decision-making. <br><br>
        (b) The effectiveness of problem solving greatly increases in settings where there is a high degree of trust and AI is
        seamlessly integrated. Businesses gain from dramatically reduced turnaround times, improved decision-making processes
        that take advantage of AI's sophisticated analytics capabilities, streamlined operations, and the ability to use AI's
        efficiency to solve problems more successfully.<br><br>
        (c) The behavior of Employees and their response to AI-driven decisions are greatly influenced by their level of trust in
        AI <a href="#r28">[28]</a>. Employees are more receptive to innovation and adjustment to change as a result of this acceptance, which
        promotes a technology culture.
    </p>

        <h3>9.2. Disadvantages</h3>

        <p>(a) Brittleness in decision systems may lead to a lack of trust in artificial intelligence. These systems become inflexible
        and complex, necessitating decisions that are frequently required in dynamic business environments. As a result, humans
        who rely on these systems may make poor choices <a href="#r29">[29]</a>. <br><br>
            (b) Trust issues in human-AI collaboration can have an impact on the interaction, resulting in resistance to using AI tools
            to incorporate AI into decision-making, limiting AI's potential benefits such as efficiency and improved
            decision-making.<br><br>
            (c) The attitude of creating an environment resistant to technological innovation and relying heavily on AI limits the
            company's ability to grow and adapt to modern technology aspects.Such an approach, which ignores new technological
            developments and diversifies strategies, can lead to stagnation and limits potential progress and adaptability in the
            rapidly changing digital environment <a href="#r30">[30]</a>.
        </p>
    </div>

    <div id="section10">
        <h2>10. Use of Machine Learning in decision-making <span style="font-size: 12px;">[Written by Farid Mammadov]</span></h2>

        <p>Decision-Aid Systems: Machine learning and artificial intelligence are now widely used in many fields <a href="#r31">[31]</a>. Judges use
        diagnostic and risk assessment tools. These resources are designed to help professionals make more informed, data-driven
        decisions.Machine Learning systems should improve human decision-making in situations where individuals lack confidence or
        expertise <a href="#r32">[32]</a>. The systems are not intended to detract from a person's performance when they make the right decision.</p>

        <p>Search engine results and other recommendations are common ways for web users to interact with Machine Learning
        algorithms. These systems are part of broader systems that include human decision-makers and institutional structures <a href="#r31">[31]</a>. Building trust in machine learning systems is critical. The most important aspect is to provide users with critical
        information about the model's performance and evaluation process.
        Based on their knowledge of logic, math, and machine learning itself, people's level of trust in ML recommendations can
        differ <a href="#r31">[31]</a><a href="#r33">[33]</a>. Information about the system, such as its data, architecture, and performance metrics, is what builds
        trust.</p>
    </div>

    <div id="section11">
        <h2>11. Conclusion <span style="font-size: 12px;">[Written by Farid Mammadov]</span></h2>

        <p>Trust-aware decision-making has emerged as an important paradigm in the fields of artificial intelligence (AI),
        robotics, and autonomous systems, combining technological sophistication with human-centered values. This approach
        emphasizes ethical, transparent, and accountable practices in AI systems, distinguishing between Trustworthy AI, which
        lays the groundwork for dependable and equitable AI, and Trust-aware decision-making, which focuses on making decision
        processes transparent, explainable, and accountable. In decentralized applications, trust-based decision-making becomes
        complex. Assessing the reliability of various data sources and making informed, real-time decisions becomes critical.
        Digital tools such as review aggregators exemplify the practical application of this concept by turning comprehensive
        information into reliable insights for users.</p>

        <p>Artificial intelligence plays a critical role in trust-based decision-making. The ability of artificial intelligence to
        process large data sets and identify patterns depends on the user's trust. Addressing the complexities of AI and the
        dynamically related challenges of human-AI integration is critical to the development of a technically sound,
        transparent, and user-friendly AI system. In today's technologically advanced world, making decisions based on trust is
        becoming increasingly important. It requires a comprehensive strategy that considers user engagement, security,
        transparency, and technical efficiency. As technology advances, reliable decision-making will become more important and
        guide the ethical and responsible creation of artificial intelligence systems. This strategy promotes sustainable
        coexistence between intelligent machines and humans by ensuring that technological advances are reliable, effective, and
        consistent with human values and expectations.</p>
    </div>

    <div class="references">
	   		<h2>12. References</h2>
    		<p class="reference" id="r1">[1] Li, B., Qi, P., Liu, B., Di, S., Liu, J., Pei, J., Yi, J., & Zhou, B. (2021). Trustworthy AI: From Principles to Practices. <a href="https://doi.org/10.48550/arXiv.2110.01167" target="_blank">https://doi.org/10.48550/arXiv.2110.01167</a></p>
    		<p class="reference" id="r2">[2] Ishmanov, Farruh & Malik, Aamir & Kim, Sung & Begalov, Bahodir. (2013). Trust management system in wireless sensor networks: Design considerations and research challenges. Transactions on Emerging Telecommunications Technologies. <a href=" https://doi.org/10.1002/ett.2674" target="_blank">https://doi.org/10.1002/ett.2674</a></p>
    		<p class="reference" id="r3">[3] Lukyanenko, R., Maass, W. & Storey, V.C. Trust in artificial intelligence: From a Foundational Trust Framework to emerging research opportunities. Electron Markets 32, 1993–2020 (2022). <a href="https://doi.org/10.1007/s12525-022-00605-4" target="_blank">https://doi.org/10.1007/s12525-022-00605-4</a></p>
    		<p class="reference" id="r4">[4] IBM Documentation (2015). 5725-W51 IBM Watson for Oncology. [Online]. Available: <a href="https://www.ibm.com/docs/en/announcements/watson-oncology#h2-smpubs" target="_blank">https://www.ibm.com/docs/en/announcements/watson-oncology#h2-smpubs</a> (06.12.2023)</p>
    		<p class="reference" id="r5">[5] Jennifer L. Malin, Envisioning Watson As a Rapid-Learning System for Oncology. JOP 9, 155-157(2013). <a href="https://doi.org/10.1200/JOP.2013.001021" target="_blank">https://doi.org/10.1200/JOP.2013.001021</a></p>
    		<p class="reference" id="r6">[6] Zhang, W., Wong, W. & Findlay, M. Trust and robotics: a multi-staged decision-making approach to robots in community. AI & Soc (2023). <a href="https://doi.org/10.1007/s00146-023-01705-1" target="_blank">https://doi.org/10.1007/s00146-023-01705-1</a></p>
    		<p class="reference" id="r7">[7] D. R. Billings, K. E. Schaefer, J. Y. C. Chen and P. A. Hancock, "Human-robot interaction: Developing trust in robots," 2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Boston, MA, USA, 2012, pp. 109-110. <a href="http://dx.doi.org/10.1145/2157689.2157709" target="_blank">http://dx.doi.org/10.1145/2157689.2157709</a></p>
    		<p class="reference" id="r8">[8] Logistics Business® Magazine (13th February 2020). Geek+ Automation Powers Same-Day Delivery for Nike Japan. [Online]. Available: <a href="https://www.logisticsbusiness.com/materials-handling-warehousing/automation-handling-systems/geek-automation-powers-same-day-delivery-for-nike-japan/" target="_blank">https://www.logisticsbusiness.com/materials-handling-warehousing/automation-handling-systems/geek-automation-powers-same-day-delivery-for-nike-japan/</a> (06.12.2023)</p>
    		<p class="reference" id="r9">[9] R. C. Arkin, P. Ulam and A. R. Wagner, "Moral Decision Making in Autonomous Systems: Enforcement, Moral Emotions, Dignity, Trust, and Deception," in Proceedings of the IEEE, vol. 100, no. 3, pp. 571-589, March 2012. <a href="http://dx.doi.org/10.1109/JPROC.2011.2173265" target="_blank">http://dx.doi.org/10.1109/JPROC.2011.2173265</a> </p>
    		<p class="reference" id="r10">[10] H. Bai, S. Cai, N. Ye, D. Hsu and W. S. Lee, "Intention-aware online POMDP planning for autonomous driving in a crowd," 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, WA, USA, 2015, pp. 454-460. <a href="https://doi.org/10.1155/2016/1025349" target="_blank">https://doi.org/10.1155/2016/1025349</a></p> 
    		<p class="reference" id="r11">[11] Mauricio Peña (July 6, 2023). The Waymo Driver is already improving road safety. [Online]. Available: <a href="https://waymo.com/blog/2023/07/the-waymo-driver-is-already-improving-road-safety/" target="_blank">https://waymo.com/blog/2023/07/the-waymo-driver-is-already-improving-road-safety/</a> (07.12.2023)</p>
    		<p class="reference" id="r12">[12] de Fine Licht, K., de Fine Licht, J. Artificial intelligence, transparency, and public decision-making. AI & Soc 35, 917–926 (2020). <a href="https://doi.org/10.1007/s00146-020-00960-w" target="_blank">https://doi.org/10.1007/s00146-020-00960-w</a></p>
    		<p class="reference" id="r13">[13] T. -M. Hsu, Y. -R. Chen and C. -H. Wang, "Decision Making Process of Autonomous Vehicle with Intention-Aware Predictionat Unsignalized Intersections," 2020 International Automatic Control Conference (CACS), Hsinchu, Taiwan, 2020. <a href="https://doi.org/10.1109/CACS50047.2020.9289815" target="_blank">https://doi.org/10.1109/CACS50047.2020.9289815</a></p>
            <p class="reference" id="r14">[14] A. Adadi and M. Berrada, "Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)," in IEEE Access, vol. 6, pp. 52138-52160, 2018. <a href="https://doi.org/10.1109/ACCESS.2018.2870052" target="_blank">https://doi.org/10.1109/ACCESS.2018.2870052</a></p>
            <p class="reference" id="r15">[15] Ren, M., Chen, N. & Qiu, H. Human-machine Collaborative Decision-making: An Evolutionary Roadmap Based on Cognitive Intelligence. Int J of Soc Robotics 15, 1101–1114 (2023). <a href="https://doi.org/10.1007/s12369-023-01020-1" target="_blank">https://doi.org/10.1007/s12369-023-01020-1</a></p>
            <p class="reference" id="r16">[16] V. Siegert, A. Kirchhoff and M. Gaedke, "ConTED: Towards Content Trust for the Decentralized Web," 2022 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), Niagara Falls, ON, Canada, 2022, pp. 604-611 <a href="https://doi.org/10.1109/WI-IAT55865.2022.00095" target="_blank">https://doi.org/10.1109/WI-IAT55865.2022.000951</a></p>
            <p class="reference" id="r17">[17] Aebeloe C. Decentralized Knowledge Graphs on the Web. Aalborg Universitetsforlag, 2022. 247 <a href="https://doi.org/10.54337/aau495046844" target="_blank">https://doi.org/10.54337/aau495046844</a></p>           
            <p class="reference" id="r18">[18] Zheng, Z., Xie, S., Dai, H.-N., Chen, X., & Wang, H. (2018). Blockchain challenges and opportunities: A survey. International Journal of Web and Grid Services, 14(4), 352-375.</p>
            <p class="reference" id="r19">[19] Fensel, D. et al. (2020). Introduction: What Is a Knowledge Graph?. In: Knowledge Graphs. Springer, Cham. <a href="https://doi.org/10.1007/978-3-030-37439-6_1" target="_blank">https://doi.org/10.1007/978-3-030-37439-6_1</a></p>
            <p class="reference" id="r20">[20] Jennifer Golbeck (2008), "Trust on the World Wide Web: A Survey", Foundations and Trends® in Web Science: Vol. 1: No. 2, pp 131-197. <a href="http://dx.doi.org/10.1561/1800000006" target="_blank">http://dx.doi.org/10.1561/1800000006</a></p>
            <p class="reference" id="r21">[21] Sambra, A.V., Mansour, E., Hawke, S., Zereba, M., Greco, N., Ghanem, A., Zagidulin, D., Aboulnaga, A., & Berners-Lee, T. (2016). Solid : A Platform for Decentralized Social Applications Based on Linked Data. <a href="https://api.semanticscholar.org/CorpusID:49564404" target="_blank">https://api.semanticscholar.org/CorpusID:49564404</a></p>
            <p class="reference" id="r22">[22] V. Siegert, M. Noura and M. Gaedke, "aTLAS: a Testbed to Examine Trust for a Redecentralized Web," 2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT), Melbourne, Australia, 2020, pp. 411-416. <a href="https://doi.org/10.1109/WIIAT50758.2020.00060" target="_blank">https://doi.org/10.1109/WIIAT50758.2020.00060</a></p>
            <p class="reference" id="r23">[23] Sun, Y. (2008). Market and Strategic Analysis of Opinion Aggregators. Working Paper CISL# 2008-02. <a href="http://web.mit.edu/smadnick/www/wp/2008-02.pdf" target="_blank">http://web.mit.edu/smadnick/www/wp/2008-02.pdf</a></p>
            <p class="reference" id="r24">[24] Alrababah, S. A. A., Gan, K. H., & Tan, T.-P. (2017). Mining opinionated product features using WordNet lexicographer files. Journal of Information Science, 43(6), 769-785. <a href="https://doi.org/10.1177/0165551516667651" target="_blank">https://doi.org/10.1177/0165551516667651</a></p>
            <p class="reference" id="r25">[25] Glikson, Ella & Woolley, Anita. (2020). Human trust in artificial intelligence: Review of empirical research. Academy of Management Annals (in press). The Academy of Management Annals.<a href="https://doi.org/10.5465/annals.2018.0057" target="_blank">https://doi.org/10.5465/annals.2018.0057</a></p>
            <p class="reference" id="r26">[26] Kolbjørnsrud, Vegard & Amico, Richard & Thomas, Robert. (2017). Partnering with AI: how organizations can win over skeptical managers. Strategy & Leadership. 45. 37-43. 10.1108/SL-12-2016-0085. <a href="https://doi.org/10.1108/SL-12-2016-0085" target="_blank">https://doi.org/10.1108/SL-12-2016-0085</a></p>
            <p class="reference" id="r27">[27] Dirks KT, Ferrin DL. Trust in leadership: meta-analytic findings and implications for research and practice. J Appl Psychol. 2002 Aug;87(4):611-28. doi: 10.1037/0021-9010.87.4.611. PMID: 12184567. <a href="https://doi.org/10.1037/0021-9010.87.4.611" target="_blank">https://doi.org/10.1037/0021-9010.87.4.611</a></p>
            <p class="reference" id="r28">[28] Zand, D. E. (1972). Trust and Managerial Problem Solving. Administrative Science Quarterly, 17(2), 229–239. <a href="https://doi.org/10.2307/2393957" target="_blank">https://doi.org/10.2307/23939571</a></p>
            <p class="reference" id="r29">[29] P. J. Smith, C. E. McCoy, and C. Layton. 1997. Brittleness in the design of cooperative problem-solving systems: the effects on user performance. Trans. Sys. Man Cyber. Part A 27, 3 (May 1997), 360–371. <a href="https://doi.org/10.1109/3468.568744" target="_blank">https://doi.org/10.1109/3468.568744</a></p>
            <p class="reference" id="r30">[30] Yu L, Li Y. Artificial Intelligence Decision-Making Transparency and Employees' Trust: The Parallel Multiple Mediating Effect of Effectiveness and Discomfort. Behav Sci (Basel). 2022 Apr 27;12(5):127. PMID: 35621424; PMCID: PMC9138134. <a href="https://doi.org/10.3390/bs12050127" target="_blank">https://doi.org/10.3390/bs12050127</a></p>
            <p class="reference" id="r31">[31] Harini Suresh, Natalie Lao, and Ilaria Liccardi. 2020. Misplaced Trust: Measuring the Interference of Machine Learning in Human Decision-Making. In Proceedings of the 12th ACM Conference on Web Science (WebSci '20). Association for Computing Machinery, New York, NY, USA, 315–324. <a href="https://doi.org/10.1145/3394231.3397922" target="_blank">https://doi.org/10.1145/3394231.3397922</a></p>
            <p class="reference" id="r32">[32] Green, B., & Chen, Y. (2019). Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments. Proceedings of the Conference on Fairness, Accountability, and Transparency. <a href="https://api.semanticscholar.org/CorpusID:54195349" target="_blank">https://api.semanticscholar.org/CorpusID:54195349</a></p>
            <p class="reference" id="r33">[33] Yin, Ming & Vaughan, Jennifer & Wallach, Hanna. (2019). Understanding the Effect of Accuracy on Trust in Machine Learning Models. CHI '19: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems. 1-12. <a href="http://dx.doi.org/10.1145/3290605.3300509" target="_blank">http://dx.doi.org/10.1145/3290605.3300509</a></p>
        </div>

</body>

</html>

