<!DOCTYPE html>
<html>

<head>
    <title>Web Engineering Seminar</title>

    <link rel="stylesheet" type="text/css" href="main.css" />
    <link href='https://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600,700' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
</head>

<body>
    <header>
        <h2>Web Engineering Seminar in Winter-semester 2023/24</h2>
        <h1>Trust-Aware Decision Making</h1>
        <h2 class="author">Shubham Manur and Farid Mammadov</h2>
        <h3 class="affiliation">
            Professur Verteilte und Selbstorganisierende Rechnersysteme<br>
            Technical University of Chemnitz<br>
            Chemnitz, Germany
        </h3>
    </header>

    <div id="section1">
        <h2>1. Introduction</h2>
        
        <p>Traditional decisions in machine learning are often made based solely on data and patterns. However, real-world
        scenarios involve a human element, that is - trust. In today's world, where everything is more connected than ever,
        trust plays a pivotal role in shaping the effectiveness and reliability of decision-making processes. Trust-aware
        decision-making acknowledges this human aspect and incorporates trust-related factors into the decision-making process.</p>
        
        <p>In various fields such as artificial intelligence, human-computer interaction, and autonomous systems, understanding and
        incorporating trust is crucial for the successful decision-making process. This approach considers the reliability,
        credibility, and past performance of the entities involved, ensuring that decisions are not only based on raw data but
        also consider the level of trustworthiness associated with the available information. But why does trust matter? In this
        report, we'll explore how integrating trust-related information into machine learning models can lead to more robust,
        transparent, and user-centric outcomes.</p>
    </div>

    <div id="section2">
        <h2>2. Trustworthy AI vs Trust-aware Decision Making.</h2>
        
        <p>While the terms Trustworthy AI and Trust-aware decision-making are often used interchangeably, they represent distinct
        yet interconnected concepts. Trustworthy AI is defined as a comprehensive framework that addresses the overall
        trustworthiness of AI systems, encompassing aspects such as accuracy, reliability, fairness, security, and transparency <a href="#r1">[1]</a>.
        Trust-aware decision-making, a subset of trustworthy AI, delves into the decision-making processes employed by AI
        systems. It emphasizes the need for transparency, explainability, and accountability in AI decision-making processes to
        foster trust and address potential biases or ethical concerns.</p>
        
        <p>The development of trustworthy AI relies on the integration of trust-aware decision-making principles. Transparency
        entails providing humans with clear explanations of AI decisions, enabling them to understand the rationale behind the
        system's actions <a href="#r1">[1]</a>. Explainability goes beyond transparency, delving into the underlying data and algorithms that
        inform AI decisions, allowing for deeper insights into the system's reasoning. Accountability ensures that AI systems
        can be held responsible for their decisions and that individuals affected by AI outcomes can seek redress if necessary <a href="#r1">[1]</a>.
        By incorporating these principles, trust-aware decision-making contributes to the creation of AI systems that are
        not only accurate and reliable but also transparent, explainable, and accountable, fostering trust and ensuring
        responsible AI development.</p>
    </div>

    <div id="section3">
        <h2>3. Key Components</h2>
        
        <p>As we delve into trust-aware decision-making, let's explore its fundamental components. Understanding these foundational
        components will help us understand how trust intertwines with decision-making.</p>
        
        <p>(a) Integration of Trust Considerations: Enhancing decision-making processes necessitates the incorporation of trust-related elements. This involves formulating
        models and algorithms capable of evaluating the trustworthiness of entities within the decision-making context, such as
        data sources, algorithms, or individuals. For example, in wireless sensor networks, trust management plays a crucial
        role in ensuring the reliability and security of data transmission and decision-making. TM schemes typically involve
        establishing trust relationships between sensor nodes based on their past behaviour and reputation. These trust
        relationships are then used to filter and prioritize data and make informed decisions about routing and resource
        allocation <a href="#r2">[2]</a>.</p>
        
        <p>(b) Multidisciplinary Application: Trust-aware decisions involve a comprehensive approach that takes into account the trustworthiness of various elements.
        This means considering the reliability and credibility of involved entities, ultimately leading to more dependable
        outcomes across diverse fields. For instance, in AI, algorithms may be designed to consider the trustworthiness of data
        sources to improve the quality of predictions or classifications. In human-computer interaction, trust is crucial for
        user acceptance and satisfaction. Autonomous systems, relying on decision-making algorithms, benefit from incorporating
        trust metrics to ensure safe and reliable operations.</p>
    </div>

    <div id="section4">
        <h2>4. Decision-making process</h2>
        
        <p>We have divided our topic into three key concepts under the umbrella of Trust-Aware Decision Making: Decision Making in
        Artificial Intelligence (AI), Robots, and Autonomous Systems. In various fields such as AI, human-computer interaction,
        and autonomous systems, understanding and incorporating trust is crucial for the successful decision-making process.</p>
        
        <h3>4.1. Decision-making in Artificial Intelligence</h3>
        
        <p>In Artificial Intelligence, advanced algorithms and complex data analysis help to optimize actions. However, trust-aware
        decision-making also plays an important role. AI systems are often opaque and difficult to understand, which can make it
        difficult for people to trust them. On the other hand, AI systems can also be designed to be more transparent and
        accountable, which can help to build trust <a href="#r3">[3]</a>.</p>
        
        <p>Exploring key aspects of trust-aware decision-making in AI, Dynamic Decision Adjustment allows AI systems to dynamically
        adapt to changing circumstances, ensuring effectiveness in unpredictable scenarios across fields like finance,
        healthcare, and autonomous systems. Explainable AI (XAI) emerges as a critical factor in cultivating trust by developing
        models that offer understandable explanations for AI decisions. This transparency is important for users, stakeholders,
        and regulatory bodies to trust and accept AI outcomes. Lastly, Human-AI Collaboration highlights how AI systems and
        human intelligence work together. While AI brings efficiency and automation, humans contribute to context, ethics, and a
        deeper understanding of complex situations <a href="#r3">[3]</a>. IBM's Watson for Oncology serves as an exemplary showcase of
        decision-making prowess in AI. It is an AI-powered system developed by IBM in collaboration with Memorial Sloan
        Kettering Cancer Center. The AI system was trained on a vast amount of medical literature, clinical trial data, and
        oncology textbooks <a href="#r4">[4]</a> <a href="#r5">[5]</a>.</p>
        
        <h3>4.2. Decision-making in Robots</h3>
        
        <p>Trust-aware decision-making in robotics extends beyond algorithms, it consists of the reliability of sensory input and
        the establishment of trust in human-robot interactions. The ongoing research in these domains is instrumental in
        ensuring the robustness, adaptability, and acceptance of robots across various applications <a href="#r6">[6]</a>.</p>
        
        <p>Moving into specific aspects, Sensor Trustworthiness examines the dependability of sensory input. This involves methods
        to evaluate and improve the trustworthiness of data collected by robot sensors, assessments of sensor accuracy,
        calibration, and real-time reliability. Adaptive Algorithms introduce the importance of adaptive decision-making
        algorithms in robotics, emphasising their capability to navigate effectively through dynamic and unpredictable
        scenarios <a href="#r7">[7]</a>. Lastly, Human-Robot Trust highlights the fundamental role of establishing trust between humans and robots
        for successful collaboration, emphasizing the significance of understanding user perceptions and trust in robotic
        actions for the effective deployment of robotic systems <a href="#r7">[7]</a>. The collaborative robot (cobot) developed by Nike stands as
        a prime illustration of decision-making capabilities in robotics. Unlike traditional robots, which are typically
        confined to cages or enclosures to prevent accidental interactions with people, cobots are equipped with sensors and
        software that allow them to detect and avoid collisions. The cobot's ability to pick and place small parts with speed
        and precision led to faster order fulfilment and reduced processing times. As a result, Nike was able to introduce
        same-day delivery to its Japanese customers <a href="#r8">[8]</a>.</p>
        
        <h3>4.3. Decision-making in Autonomous systems</h3>
        
        <p>As humans increasingly rely on autonomous systems to make decisions, it is crucial to ensure that these systems are
        trustworthy. Trust is a complex concept that involves several factors, including reliability, predictability, and
        fairness. In the context of autonomous systems, trust also depends on the system's ability to make decisions that are
        aligned with human values and expectations <a href="#r9">[9]</a>.</p>
        
        <p>There are several ways in which an autonomous system can incorporate trust into its decision-making process. Some of
        them are - Environmental data trust metrics, which are crucial for assessing the reliability of environmental data
        inputs. Various Studies focus on developing methods to evaluate and enhance the trustworthiness of data used by
        autonomous systems <a href="#r9">[9]</a>. Additionally, decentralised trust models allow them to make collaborative decisions based on
        trust assessments within a network. This collaborative approach enhances the overall trustworthiness of decision-making
        in the transportation system. Lastly, continuous learning and trust adaptation, trust in autonomous systems is not
        static but evolves based on experience and interactions. Trust-aware decision models should continuously learn from
        their environment and interactions, adapting their trust assessments and decision-making strategies accordingly <a href="#r9">[9]</a> <a href="#r10">[10]</a>.
        Waymo, a subsidiary of Alphabet Inc., stands at the forefront of autonomous driving technology, developing vehicles
        capable of navigating complex real-world environments without human intervention. To achieve this level of
        sophistication, Waymo employs a robust trust-aware decision-making framework that prioritises safety, transparency, and
        adaptability <a href="#r11">[11]</a>.</p>
    </div>

    <div id="section5">
        <h2>5. Creating Trust-aware decisions</h2>
        
        <p>Having examined the previously mentioned aspects, we can incorporate trust-aware decision-making in diverse ways, with
        notable concepts including:</p>
        
        <p>(a) Transparency: Achieving trust in decision-making begins with transparency. Transparent systems provide users with
        clear insights into the decision-making processes, ensuring that the rationale behind each decision is easily
        understandable. Users are more likely to trust decisions when they can trace and comprehend the steps leading to the
        outcome <a href="#r3">[3]</a> <a href="#r12">[12]</a>.</p>
        
        <p>(b) Adaptive Decision-Making: Trust-aware decisions should be adaptive to changing circumstances and evolving
        information. Adaptive decision-making involves the capability to dynamically adjust strategies based on real-time
        feedback and alterations in the environment. By incorporating learning algorithms and continuous monitoring, systems can
        respond to shifts in trust levels, ensuring that decisions remain relevant and reliable over time <a href="#r7">[7]</a>.</p>
        
        <p>(c) Diversify Inputs: Building trust requires considering a diverse range of inputs. Instead of relying on a single
        source or type of information, trust-aware decisions benefit from the integration of varied and complementary data
        inputs <a href="#r13">[13]</a>.</p>
        
        <p>(d) Explainability Techniques: Trust is closely tied to the ability to explain decisions effectively. Explainability
        techniques aim to make complex decision-making processes more understandable to users. Techniques such as feature
        importance analysis, model-agnostic interpretability methods, and interactive visualizations contribute to a transparent
        and interpretable decision-making framework. Explainability is a key factor in building user confidence and acceptance
        of automated decision-making systems <a href="#r14">[14]</a>.</p>
    </div>

    <div id="section6">
        <h2>6. Challenges and Drawbacks</h2>
        
        <p>Trust-aware decision-making, while a crucial and evolving field, is not without its drawbacks.
        The following drawbacks highlight some of the key concerns in this domain:</p>
        
        <p>(a) Lack of Transparency and Explainability: One of the foremost challenges in trust-aware decision-making is the lack
        of transparency and explainability. When decision-making processes are opaque or difficult to understand(that is black
        box), users may struggle to trust the outcomes. Overcoming this challenge involves developing effective strategies for
        making decision-making processes transparent and implementing explainability techniques to bridge the gap between
        complex algorithms and user comprehension <a href="#r4">[4]</a> <a href="#r14">[14]</a>.</p>
        
        <p>(b) Security Concerns: Security issues pose a significant challenge to trust-aware decision-making systems. As these
        systems often handle sensitive data and make critical decisions, they become potential targets for malicious activities
        such as hacking or tampering. Ensuring robust cybersecurity measures, including encryption, secure data storage, and
        access controls, is essential for the reliability and safety of decision-making processes <a href="#r2">[2]</a>.</p>
        
        <p>(c) Human-AI Collaboration: Users may be hesitant to trust decisions made by AI systems, particularly in situations
        where the consequences are significant. Striking the right balance between human intuition and AI-driven insights is a
        delicate task. Balancing the roles of humans and AI to maximize their respective strengths while addressing potential
        biases or misunderstandings is critical for fostering trust in these collaborative environments <a href="#r9">[9]</a> <a href="#r15">[15]</a>.</p>
    </div>

    <div class="references">
	   		<h2>#. References</h2>
    		<p class="reference" id="r1">[1] Li, B., Qi, P., Liu, B., Di, S., Liu, J., Pei, J., Yi, J., & Zhou, B. (2021). Trustworthy AI: From Principles to Practices. <a href="https://doi.org/10.48550/arXiv.2110.01167" target="_blank">https://doi.org/10.48550/arXiv.2110.01167</a></p>
    		<p class="reference" id="r2">[2] Ishmanov, Farruh & Malik, Aamir & Kim, Sung & Begalov, Bahodir. (2013). Trust management system in wireless sensor networks: Design considerations and research challenges. Transactions on Emerging Telecommunications Technologies. <a href=" https://doi.org/10.1002/ett.2674" target="_blank">https://doi.org/10.1002/ett.2674</a></p>
    		<p class="reference" id="r3">[3] Lukyanenko, R., Maass, W. & Storey, V.C. Trust in artificial intelligence: From a Foundational Trust Framework to emerging research opportunities. Electron Markets 32, 1993–2020 (2022). <a href="https://doi.org/10.1007/s12525-022-00605-4" target="_blank">https://doi.org/10.1007/s12525-022-00605-4</a></p>
    		<p class="reference" id="r4">[4] IBM Documentation (2015). 5725-W51 IBM Watson for Oncology. [Online]. Available: <a href="https://www.ibm.com/docs/en/announcements/watson-oncology#h2-smpubs" target="_blank">https://www.ibm.com/docs/en/announcements/watson-oncology#h2-smpubs</a> (06.12.2023)</p>
    		<p class="reference" id="r5">[5] Jennifer L. Malin, Envisioning Watson As a Rapid-Learning System for Oncology. JOP 9, 155-157(2013). <a href="https://doi.org/10.1200/JOP.2013.001021" target="_blank">https://doi.org/10.1200/JOP.2013.001021</a></p>
    		<p class="reference" id="r6">[6] Zhang, W., Wong, W. & Findlay, M. Trust and robotics: a multi-staged decision-making approach to robots in community. AI & Soc (2023). <a href="https://doi.org/10.1007/s00146-023-01705-1" target="_blank">https://doi.org/10.1007/s00146-023-01705-1</a></p>
    		<p class="reference" id="r7">[7] D. R. Billings, K. E. Schaefer, J. Y. C. Chen and P. A. Hancock, "Human-robot interaction: Developing trust in robots," 2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI), Boston, MA, USA, 2012, pp. 109-110. <a href="http://dx.doi.org/10.1145/2157689.2157709" target="_blank">http://dx.doi.org/10.1145/2157689.2157709</a></p>
    		<p class="reference" id="r8">[8] Logistics Business® Magazine (13th February 2020). Geek+ Automation Powers Same-Day Delivery for Nike Japan. [Online]. Available: <a href="https://www.logisticsbusiness.com/materials-handling-warehousing/automation-handling-systems/geek-automation-powers-same-day-delivery-for-nike-japan/" target="_blank">https://www.logisticsbusiness.com/materials-handling-warehousing/automation-handling-systems/geek-automation-powers-same-day-delivery-for-nike-japan/</a> (06.12.2023)</p>
    		<p class="reference" id="r9">[9] R. C. Arkin, P. Ulam and A. R. Wagner, "Moral Decision Making in Autonomous Systems: Enforcement, Moral Emotions, Dignity, Trust, and Deception," in Proceedings of the IEEE, vol. 100, no. 3, pp. 571-589, March 2012. <a href="http://dx.doi.org/10.1109/JPROC.2011.2173265" target="_blank">http://dx.doi.org/10.1109/JPROC.2011.2173265</a> </p>
    		<p class="reference" id="r10">[10] H. Bai, S. Cai, N. Ye, D. Hsu and W. S. Lee, "Intention-aware online POMDP planning for autonomous driving in a crowd," 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, WA, USA, 2015, pp. 454-460. <a href="https://doi.org/10.1155/2016/1025349" target="_blank">https://doi.org/10.1155/2016/1025349</a></p> 
    		<p class="reference" id="r11">[11] Mauricio Peña (July 6, 2023). The Waymo Driver is already improving road safety. [Online]. Available: <a href="https://waymo.com/blog/2023/07/the-waymo-driver-is-already-improving-road-safety/" target="_blank">https://waymo.com/blog/2023/07/the-waymo-driver-is-already-improving-road-safety/</a> (07.12.2023)</p>
    		<p class="reference" id="r12">[12] de Fine Licht, K., de Fine Licht, J. Artificial intelligence, transparency, and public decision-making. AI & Soc 35, 917–926 (2020). <a href="https://doi.org/10.1007/s00146-020-00960-w" target="_blank">https://doi.org/10.1007/s00146-020-00960-w</a></p>
    		<p class="reference" id="r13">[13] T. -M. Hsu, Y. -R. Chen and C. -H. Wang, "Decision Making Process of Autonomous Vehicle with Intention-Aware Predictionat Unsignalized Intersections," 2020 International Automatic Control Conference (CACS), Hsinchu, Taiwan, 2020. <a href="https://doi.org/10.1109/CACS50047.2020.9289815" target="_blank">https://doi.org/10.1109/CACS50047.2020.9289815</a></p>
            <p class="reference" id="r14">[14] A. Adadi and M. Berrada, "Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)," in IEEE Access, vol. 6, pp. 52138-52160, 2018. <a href="https://doi.org/10.1109/ACCESS.2018.2870052" target="_blank">https://doi.org/10.1109/ACCESS.2018.2870052</a></p>
            <p class="reference" id="r15">[15] Ren, M., Chen, N. & Qiu, H. Human-machine Collaborative Decision-making: An Evolutionary Roadmap Based on Cognitive Intelligence. Int J of Soc Robotics 15, 1101–1114 (2023). <a href="https://doi.org/10.1007/s12369-023-01020-1" target="_blank">https://doi.org/10.1007/s12369-023-01020-1</a></p>
    </div>

</body>

</html>

